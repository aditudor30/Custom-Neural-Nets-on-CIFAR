{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b797fb02",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "022f73a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cuda')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ca526d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ]\n",
    ")\n",
    "\n",
    "test_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471e9345",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.CIFAR10('./data', train = True, transform=train_transform, download = True)\n",
    "trainloader = DataLoader(trainset,batch_size = 64, shuffle = True, num_workers = 2)\n",
    "\n",
    "testset = datasets.CIFAR10('./data', train = False, transform = test_transform, download=True)\n",
    "testloader = DataLoader(testset, batch_size=64, shuffle = False, num_workers = 2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f529ffbe",
   "metadata": {},
   "source": [
    "The VGG-net concept is the following:\n",
    "    1. It can be a deeper arhitecture\n",
    "    2. Every important block (fully connected layers not included) have 2 convolutional layers and only 1 pooling layer\n",
    "    3. The first convolution layer in a block is classic(output channels > input channels) but the 2nd one has the same amount of channels in the input and output\n",
    "        - Why is this important? Well, having two convolutional layers with a kernel size = 3 (3x3) but the same amount of features as implementing one convolutional layer means that the actual output is similar to a convolutional layer with a kernel size = 5 and with more understanding of the features (having more connections in this case means more \"intelligence\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "00208cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class vgg_model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.block1 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=3, out_channels=32, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride = 2),\n",
    "            nn.Dropout(0.2)\n",
    "        )\n",
    "        self.block2 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=64, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=128, out_channels=128, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(128),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.3)\n",
    "        )\n",
    "        self.block3 = nn.Sequential(\n",
    "            nn.Conv2d(in_channels=128, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(in_channels=256, out_channels=256, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(256),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Dropout(0.4)\n",
    "        )\n",
    "\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(256*4*4, 1024),\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.5),\n",
    "            nn.Linear(1024, 10)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.block1(x)\n",
    "        x = self.block2(x)\n",
    "        x = self.block3(x)\n",
    "        x = self.fc(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ddc6f397",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "vgg_model(\n",
       "  (block1): Sequential(\n",
       "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (block2): Sequential(\n",
       "    (0): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.3, inplace=False)\n",
       "  )\n",
       "  (block3): Sequential(\n",
       "    (0): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (2): ReLU()\n",
       "    (3): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (5): ReLU()\n",
       "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "    (7): Dropout(p=0.4, inplace=False)\n",
       "  )\n",
       "  (fc): Sequential(\n",
       "    (0): Flatten(start_dim=1, end_dim=-1)\n",
       "    (1): Linear(in_features=4096, out_features=1024, bias=True)\n",
       "    (2): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): ReLU()\n",
       "    (4): Dropout(p=0.5, inplace=False)\n",
       "    (5): Linear(in_features=1024, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = vgg_model().to(device)\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b6fdf970",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.001, momentum=0.9, weight_decay=5e-4)\n",
    "scheduler = StepLR(optimizer, step_size=20, gamma = 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f4aedab5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50 | Loss: 1.6958\n",
      "Epoch 2/50 | Loss: 1.3541\n",
      "Epoch 3/50 | Loss: 1.1904\n",
      "Epoch 4/50 | Loss: 1.0727\n",
      "Epoch 5/50 | Loss: 0.9895\n",
      "Epoch 6/50 | Loss: 0.9235\n",
      "Epoch 7/50 | Loss: 0.8692\n",
      "Epoch 8/50 | Loss: 0.8302\n",
      "Epoch 9/50 | Loss: 0.7871\n",
      "Epoch 10/50 | Loss: 0.7636\n",
      "Epoch 11/50 | Loss: 0.7361\n",
      "Epoch 12/50 | Loss: 0.7144\n",
      "Epoch 13/50 | Loss: 0.6851\n",
      "Epoch 14/50 | Loss: 0.6625\n",
      "Epoch 15/50 | Loss: 0.6520\n",
      "Epoch 16/50 | Loss: 0.6253\n",
      "Epoch 17/50 | Loss: 0.6106\n",
      "Epoch 18/50 | Loss: 0.5972\n",
      "Epoch 19/50 | Loss: 0.5836\n",
      "Epoch 20/50 | Loss: 0.5748\n",
      "Epoch 21/50 | Loss: 0.5318\n",
      "Epoch 22/50 | Loss: 0.5237\n",
      "Epoch 23/50 | Loss: 0.5199\n",
      "Epoch 24/50 | Loss: 0.5146\n",
      "Epoch 25/50 | Loss: 0.5033\n",
      "Epoch 26/50 | Loss: 0.4954\n",
      "Epoch 27/50 | Loss: 0.4878\n",
      "Epoch 28/50 | Loss: 0.4863\n",
      "Epoch 29/50 | Loss: 0.4846\n",
      "Epoch 30/50 | Loss: 0.4732\n",
      "Epoch 31/50 | Loss: 0.4750\n",
      "Epoch 32/50 | Loss: 0.4634\n",
      "Epoch 33/50 | Loss: 0.4616\n",
      "Epoch 34/50 | Loss: 0.4537\n",
      "Epoch 35/50 | Loss: 0.4482\n",
      "Epoch 36/50 | Loss: 0.4442\n",
      "Epoch 37/50 | Loss: 0.4432\n",
      "Epoch 38/50 | Loss: 0.4374\n",
      "Epoch 39/50 | Loss: 0.4337\n",
      "Epoch 40/50 | Loss: 0.4278\n",
      "Epoch 41/50 | Loss: 0.4079\n",
      "Epoch 42/50 | Loss: 0.4042\n",
      "Epoch 43/50 | Loss: 0.3970\n",
      "Epoch 44/50 | Loss: 0.4020\n",
      "Epoch 45/50 | Loss: 0.3932\n",
      "Epoch 46/50 | Loss: 0.3934\n",
      "Epoch 47/50 | Loss: 0.3917\n",
      "Epoch 48/50 | Loss: 0.3941\n",
      "Epoch 49/50 | Loss: 0.3858\n",
      "Epoch 50/50 | Loss: 0.3873\n"
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for inputs, labels in trainloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    scheduler.step()\n",
    "    print(f\"Epoch {epoch+1}/{epochs} | Loss: {running_loss/len(trainloader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9778e023",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 87.81%\n"
     ]
    }
   ],
   "source": [
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in testloader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted==labels).sum().item()\n",
    "acc = 100 * correct/total\n",
    "print(f\"Test accuracy: {acc}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2ff8321",
   "metadata": {},
   "source": [
    "The accuracy of this custom made model is way higher than the ones that are not following a state-of-the-art arhitecture.\n",
    "If we want a better outcome, we have to use a model that has a ResNet-like arhitecture or use transfer learning (which in this case is not really a learning experience)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6caf3612",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = './vgg_model.pth'\n",
    "torch.save(model.state_dict(), path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plant_disease",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.24"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
